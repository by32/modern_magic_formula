name: üîç Data Quality Monitor
# Continuous monitoring of data quality and system health

on:
  schedule:
    # Run daily at 12 PM UTC to check data quality
    - cron: '0 12 * * *'
  
  # Trigger after ETL updates
  workflow_run:
    workflows: ["üìä Monthly ETL Update", "üìÖ Quarterly Rebalance"]
    types: [completed]
  
  workflow_dispatch:

jobs:
  quality-monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: üì• Checkout Repository
      uses: actions/checkout@v4
      
    - name: üêç Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: üì¶ Install UV Package Manager
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
        
    - name: üîß Install Dependencies
      run: |
        uv sync  # Install all dependencies
        
    - name: üîç Run Data Quality Checks
      id: quality
      run: |
        echo "üîç Running comprehensive data quality monitoring..."
        
        uv run python -c "
        import pandas as pd
        import os
        from datetime import datetime, timedelta
        import json
        import sys
        sys.path.append('.')
        
        # Simple quality check without complex monitoring
        def simple_quality_check(data_file):
            try:
                data = pd.read_csv(data_file)
                
                # Basic quality metrics
                total_stocks = len(data)
                missing_tickers = data['ticker'].isnull().sum()
                missing_fundamentals = (
                    data['earnings_yield'].isnull().sum() + 
                    data['roc'].isnull().sum() + 
                    data['f_score'].isnull().sum()
                ) / 3
                
                quality_score = max(0, 1.0 - (missing_fundamentals / total_stocks))
                
                return {
                    'overall_score': quality_score,
                    'record_count': total_stocks,
                    'anomalies': [],
                    'alerts': [] if quality_score >= 0.7 else ['Low quality score'],
                    'has_alerts': quality_score < 0.7,
                    'has_anomalies': False
                }
            except Exception as e:
                return {
                    'overall_score': 0.0,
                    'record_count': 0,
                    'anomalies': [f'Data loading error: {str(e)}'],
                    'alerts': ['Failed to load data'],
                    'has_alerts': True,
                    'has_anomalies': True
                }
        
        # Check if data files exist
        data_file = 'data/latest_screening_hybrid.csv'
        if not os.path.exists(data_file):
            print('‚ùå Data file not found - ETL may not have run yet')
            # Create a minimal report indicating no data
            report = {
                'timestamp': datetime.now().isoformat(),
                'quality_score': 0.0,
                'stock_count': 0,
                'data_age_days': 999,
                'anomalies': ['Data file not found'],
                'alerts': ['ETL needs to run first'],
                'status': 'NO_DATA'
            }
            with open('quality_report.json', 'w') as f:
                json.dump(report, f, indent=2)
            
            with open('quality_summary.txt', 'w') as f:
                f.write('Quality Score: N/A\\n')
                f.write('Stock Count: 0\\n')
                f.write('Status: NO_DATA\\n')
                f.write('Error: Data file not found - ETL needs to run first\\n')
            
            print('üìù Created placeholder reports - ETL needs to run first')
            exit(0)  # Exit successfully but with no data
        
        # Check data age
        file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(data_file))
        if file_age > timedelta(days=35):  # Allow 35 days for monthly updates
            print(f'‚ö†Ô∏è Data is stale: {file_age.days} days old')
        
        # Load and analyze data
        data = pd.read_csv(data_file)
        print(f'üìä Dataset: {len(data)} stocks')
        
        # Run quality monitoring
        results = simple_quality_check(data_file)
        
        quality_score = results.get('overall_score', 0)
        anomalies = results.get('anomalies', [])
        alerts = results.get('alerts', [])
        
        print(f'üîç Quality Score: {quality_score:.1%}')
        print(f'üö® Anomalies: {len(anomalies)}')
        print(f'‚ö†Ô∏è Alerts: {len(alerts)}')
        
        # Create quality report
        report = {
            'timestamp': datetime.now().isoformat(),
            'quality_score': quality_score,
            'stock_count': len(data),
            'data_age_days': file_age.days,
            'anomalies': anomalies,
            'alerts': alerts,
            'status': 'PASS' if quality_score >= 0.75 and len(alerts) == 0 else 'FAIL'
        }
        
        # Save quality report
        with open('quality_report.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        # Set outputs for subsequent steps
        with open('quality_summary.txt', 'w') as f:
            f.write(f'Quality Score: {quality_score:.1%}\\n')
            f.write(f'Stock Count: {len(data)}\\n')
            f.write(f'Status: {report[\"status\"]}\\n')
            if anomalies:
                f.write(f'Anomalies: {len(anomalies)}\\n')
            if alerts:
                f.write(f'Alerts: {len(alerts)}\\n')
        
        # Exit with error code if quality is poor
        if quality_score < 0.70 or len(alerts) > 3:
            print('‚ùå Quality check failed')
            exit(1)
        else:
            print('‚úÖ Quality check passed')
        " || echo "quality_failed=true" >> $GITHUB_OUTPUT
        
    - name: üìä Generate Quality Dashboard
      if: always()
      run: |
        echo "üìä Generating quality dashboard..."
        
        # Ensure quality_report.json exists
        if [ ! -f quality_report.json ]; then
          echo '{"status": "ERROR", "quality_score": 0, "stock_count": 0, "data_age_days": 0, "anomalies": ["Report generation failed"], "alerts": ["Check logs"], "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%S")'"}' > quality_report.json
        fi
        
        uv run python -c "
        import pandas as pd
        import json
        from datetime import datetime
        
        # Load quality report
        with open('quality_report.json', 'r') as f:
            report = json.load(f)
        
        # Simple history (for now, just current entry)
        history = [report]
        
        # Generate dashboard
        dashboard = f'''# üìä Data Quality Dashboard
        
        **Current Status**: {'‚úÖ HEALTHY' if report['status'] == 'PASS' else '‚ùå ISSUES DETECTED'}
        
        ## üîç Latest Quality Metrics
        
        | Metric | Value | Status |
        |--------|-------|--------|
        | Quality Score | {report['quality_score']:.1%} | {'‚úÖ' if report['quality_score'] >= 0.80 else '‚ö†Ô∏è' if report['quality_score'] >= 0.70 else '‚ùå'} |
        | Stock Count | {report['stock_count']:,} | {'‚úÖ' if report['stock_count'] >= 100 else '‚ö†Ô∏è'} |
        | Data Age | {report['data_age_days']} days | {'‚úÖ' if report['data_age_days'] <= 32 else '‚ö†Ô∏è'} |
        | Anomalies | {len(report['anomalies'])} | {'‚úÖ' if len(report['anomalies']) == 0 else '‚ö†Ô∏è'} |
        | Alerts | {len(report['alerts'])} | {'‚úÖ' if len(report['alerts']) == 0 else '‚ùå'} |
        
        '''
        
        if report['anomalies']:
            dashboard += f'''
        ## üö® Detected Anomalies
        '''
            for anomaly in report['anomalies']:
                dashboard += f'\\n- ‚ö†Ô∏è {anomaly}'
        
        if report['alerts']:
            dashboard += f'''
        ## ‚ö†Ô∏è Active Alerts
        '''
            for alert in report['alerts']:
                dashboard += f'\\n- üö® {alert}'
        
        dashboard += f'''
        ## üìà Current Status
        
        | Metric | Value |
        |--------|-------|
        | Quality Score | {report['quality_score']:.1%} |
        | Stock Count | {report['stock_count']:,} |
        | Data Age | {report['data_age_days']} days |
        | Last Updated | {datetime.fromisoformat(report['timestamp']).strftime('%Y-%m-%d %H:%M UTC')} |'''
        
        dashboard += f'''
        
        ## üéØ Recommendations
        
        '''
        
        if report['quality_score'] >= 0.85:
            dashboard += '‚úÖ **Excellent data quality** - No action needed\\n'
        elif report['quality_score'] >= 0.75:
            dashboard += '‚ö†Ô∏è **Good data quality** - Monitor for declining trends\\n'
        else:
            dashboard += '‚ùå **Poor data quality** - Investigation required\\n'
        
        if report['data_age_days'] > 32:
            dashboard += 'üìÖ **Stale data detected** - Run ETL update\\n'
            
        if len(report['anomalies']) > 0:
            dashboard += f'üîç **{len(report[\"anomalies\"])} anomalies detected** - Review data sources\\n'
        
        dashboard += f'''
        
        ---
        *Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')} | [View Streamlit App](https://modernmagicformula.streamlit.app)*
        '''
        
        with open('quality_dashboard.md', 'w') as f:
            f.write(dashboard)
            
        print('üìä Quality dashboard generated')
        "
        
        # Ensure all files exist
        if [ ! -f quality_summary.txt ]; then
          echo "Quality Score: 0%" > quality_summary.txt
          echo "Stock Count: 0" >> quality_summary.txt
          echo "Status: ERROR" >> quality_summary.txt
          echo "Error: Quality check failed to run" >> quality_summary.txt
        fi
        
        if [ ! -f quality_dashboard.md ]; then
          echo "# üìä Data Quality Dashboard" > quality_dashboard.md
          echo "" >> quality_dashboard.md
          echo "**Status**: ‚ùå ERROR - Quality check failed to run" >> quality_dashboard.md
          echo "" >> quality_dashboard.md
          echo "Please check the workflow logs for details." >> quality_dashboard.md
        fi
        
    - name: üö® Alert on Quality Issues
      if: steps.quality.outputs.quality_failed == 'true'
      run: |
        echo "üö® Data quality issues detected!"
        
        # Read quality summary
        cat quality_summary.txt
        
        echo ""
        echo "üîó Detailed report: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        
        # In production, you would send alerts here:
        # - Create GitHub issue
        # - Send Slack notification
        # - Email alert
        # - Discord webhook
        
        echo "üí° Configure alert webhooks for production notifications"
        
    - name: üì§ Upload Quality Reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quality-report-${{ github.run_number }}
        path: |
          quality_report.json
          quality_dashboard.md
          quality_summary.txt
        retention-days: 60
        
    - name: üíæ Update Quality Dashboard
      if: success()
      run: |
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Commit quality dashboard
        git add quality_dashboard.md
        
        if ! git diff --staged --quiet; then
          git commit -m "üìä Update data quality dashboard
          
          Quality monitoring results:
          - $(grep 'Quality Score:' quality_summary.txt)
          - $(grep 'Stock Count:' quality_summary.txt)
          - $(grep 'Status:' quality_summary.txt)
          
          ü§ñ Automated quality monitoring"
          
          git push
          echo "‚úÖ Quality dashboard updated"
        fi