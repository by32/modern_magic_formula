name: ğŸ” Data Quality Monitor
# Continuous monitoring of data quality and system health

on:
  schedule:
    # Run daily at 12 PM UTC to check data quality
    - cron: '0 12 * * *'
  
  # Trigger after ETL updates
  workflow_run:
    workflows: ["ğŸ“Š Monthly ETL Update", "ğŸ“… Quarterly Rebalance"]
    types: [completed]
  
  workflow_dispatch:

jobs:
  quality-monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: ğŸ“¦ Install UV Package Manager
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
        
    - name: ğŸ”§ Install Dependencies
      run: |
        uv sync  # Install all dependencies
        
    - name: ğŸ” Run Data Quality Checks
      id: quality
      run: |
        echo "ğŸ” Running comprehensive data quality monitoring..."
        
        # Create quality check script as a file to avoid inline complexity
        cat > check_quality.py << 'EOF'
import pandas as pd
import os
from datetime import datetime, timedelta
import json
import sys

print("Starting quality check...")

# Check if data files exist
data_file = 'data/latest_screening_hybrid.csv'

if not os.path.exists(data_file):
    print('âŒ Data file not found - ETL may not have run yet')
    # Create a minimal report indicating no data
    report = {
        'timestamp': datetime.now().isoformat(),
        'quality_score': 0.0,
        'stock_count': 0,
        'data_age_days': 999,
        'anomalies': ['Data file not found'],
        'alerts': ['ETL needs to run first'],
        'status': 'NO_DATA'
    }
    with open('quality_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    with open('quality_summary.txt', 'w') as f:
        f.write('Quality Score: N/A\n')
        f.write('Stock Count: 0\n')
        f.write('Status: NO_DATA\n')
        f.write('Error: Data file not found - ETL needs to run first\n')
    
    print('ğŸ“ Created placeholder reports - ETL needs to run first')
    sys.exit(0)  # Exit successfully but with no data

try:
    # Check data age
    file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(data_file))
    age_days = file_age.days
    if age_days > 35:  # Allow 35 days for monthly updates
        print(f'âš ï¸ Data is stale: {age_days} days old')
    
    # Load and analyze data
    print(f"Loading data from {data_file}")
    data = pd.read_csv(data_file)
    print(f'ğŸ“Š Dataset: {len(data)} stocks')
    
    # Calculate quality metrics
    total_stocks = len(data)
    
    # Check for missing critical fields
    critical_fields = ['ticker', 'earnings_yield', 'roc', 'f_score']
    missing_counts = {}
    for field in critical_fields:
        if field in data.columns:
            missing_counts[field] = data[field].isnull().sum()
        else:
            missing_counts[field] = total_stocks
    
    # Calculate quality score
    total_missing = sum(missing_counts.values())
    total_possible = total_stocks * len(critical_fields)
    quality_score = max(0, 1.0 - (total_missing / total_possible)) if total_possible > 0 else 0
    
    # Determine alerts and anomalies
    anomalies = []
    alerts = []
    
    if quality_score < 0.7:
        alerts.append(f'Low quality score: {quality_score:.1%}')
    
    for field, count in missing_counts.items():
        if count > total_stocks * 0.1:  # More than 10% missing
            anomalies.append(f'{field}: {count} missing values')
    
    print(f'ğŸ” Quality Score: {quality_score:.1%}')
    print(f'ğŸš¨ Anomalies: {len(anomalies)}')
    print(f'âš ï¸ Alerts: {len(alerts)}')
    
    # Create quality report
    report = {
        'timestamp': datetime.now().isoformat(),
        'quality_score': quality_score,
        'stock_count': total_stocks,
        'data_age_days': age_days,
        'anomalies': anomalies,
        'alerts': alerts,
        'status': 'PASS' if quality_score >= 0.75 and len(alerts) == 0 else 'FAIL'
    }
    
    # Save quality report
    with open('quality_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    # Save summary
    with open('quality_summary.txt', 'w') as f:
        f.write(f'Quality Score: {quality_score:.1%}\n')
        f.write(f'Stock Count: {total_stocks}\n')
        f.write(f'Status: {report["status"]}\n')
        if anomalies:
            f.write(f'Anomalies: {len(anomalies)}\n')
        if alerts:
            f.write(f'Alerts: {len(alerts)}\n')
    
    # Determine exit code
    if quality_score < 0.70 or len(alerts) > 3:
        print('âŒ Quality check failed')
        sys.exit(1)
    else:
        print('âœ… Quality check passed')
        sys.exit(0)

except Exception as e:
    print(f"ERROR: Failed to run quality check: {str(e)}")
    import traceback
    traceback.print_exc()
    
    # Create error report
    error_report = {
        'timestamp': datetime.now().isoformat(),
        'quality_score': 0.0,
        'stock_count': 0,
        'data_age_days': 0,
        'anomalies': [f'Exception: {str(e)}'],
        'alerts': ['Quality check crashed'],
        'status': 'ERROR'
    }
    
    with open('quality_report.json', 'w') as f:
        json.dump(error_report, f, indent=2)
    
    with open('quality_summary.txt', 'w') as f:
        f.write('Quality Score: ERROR\n')
        f.write('Stock Count: 0\n')
        f.write('Status: ERROR\n')
        f.write(f'Error: {str(e)}\n')
    
    sys.exit(1)
EOF
        
        # Run the Python script
        uv run python check_quality.py || echo "quality_failed=true" >> $GITHUB_OUTPUT
        
    - name: ğŸ“Š Generate Quality Dashboard
      if: always()
      run: |
        echo "ğŸ“Š Generating quality dashboard..."
        
        # Ensure quality_report.json exists
        if [ ! -f quality_report.json ]; then
          echo '{"status": "ERROR", "quality_score": 0, "stock_count": 0, "data_age_days": 0, "anomalies": ["Report generation failed"], "alerts": ["Check logs"], "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%S")'"}' > quality_report.json
        fi
        
        uv run python -c "
        import pandas as pd
        import json
        from datetime import datetime
        
        # Load quality report
        with open('quality_report.json', 'r') as f:
            report = json.load(f)
        
        # Simple history (for now, just current entry)
        history = [report]
        
        # Generate dashboard
        dashboard = f'''# ğŸ“Š Data Quality Dashboard
        
        **Current Status**: {'âœ… HEALTHY' if report['status'] == 'PASS' else 'âŒ ISSUES DETECTED'}
        
        ## ğŸ” Latest Quality Metrics
        
        | Metric | Value | Status |
        |--------|-------|--------|
        | Quality Score | {report['quality_score']:.1%} | {'âœ…' if report['quality_score'] >= 0.80 else 'âš ï¸' if report['quality_score'] >= 0.70 else 'âŒ'} |
        | Stock Count | {report['stock_count']:,} | {'âœ…' if report['stock_count'] >= 100 else 'âš ï¸'} |
        | Data Age | {report['data_age_days']} days | {'âœ…' if report['data_age_days'] <= 32 else 'âš ï¸'} |
        | Anomalies | {len(report['anomalies'])} | {'âœ…' if len(report['anomalies']) == 0 else 'âš ï¸'} |
        | Alerts | {len(report['alerts'])} | {'âœ…' if len(report['alerts']) == 0 else 'âŒ'} |
        
        '''
        
        if report['anomalies']:
            dashboard += f'''
        ## ğŸš¨ Detected Anomalies
        '''
            for anomaly in report['anomalies']:
                dashboard += f'\\n- âš ï¸ {anomaly}'
        
        if report['alerts']:
            dashboard += f'''
        ## âš ï¸ Active Alerts
        '''
            for alert in report['alerts']:
                dashboard += f'\\n- ğŸš¨ {alert}'
        
        dashboard += f'''
        ## ğŸ“ˆ Current Status
        
        | Metric | Value |
        |--------|-------|
        | Quality Score | {report['quality_score']:.1%} |
        | Stock Count | {report['stock_count']:,} |
        | Data Age | {report['data_age_days']} days |
        | Last Updated | {datetime.fromisoformat(report['timestamp']).strftime('%Y-%m-%d %H:%M UTC')} |'''
        
        dashboard += f'''
        
        ## ğŸ¯ Recommendations
        
        '''
        
        if report['quality_score'] >= 0.85:
            dashboard += 'âœ… **Excellent data quality** - No action needed\\n'
        elif report['quality_score'] >= 0.75:
            dashboard += 'âš ï¸ **Good data quality** - Monitor for declining trends\\n'
        else:
            dashboard += 'âŒ **Poor data quality** - Investigation required\\n'
        
        if report['data_age_days'] > 32:
            dashboard += 'ğŸ“… **Stale data detected** - Run ETL update\\n'
            
        if len(report['anomalies']) > 0:
            dashboard += f'ğŸ” **{len(report[\"anomalies\"])} anomalies detected** - Review data sources\\n'
        
        dashboard += f'''
        
        ---
        *Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')} | [View Streamlit App](https://modernmagicformula.streamlit.app)*
        '''
        
        with open('quality_dashboard.md', 'w') as f:
            f.write(dashboard)
            
        print('ğŸ“Š Quality dashboard generated')
        "
        
        # Ensure all files exist
        if [ ! -f quality_summary.txt ]; then
          echo "Quality Score: 0%" > quality_summary.txt
          echo "Stock Count: 0" >> quality_summary.txt
          echo "Status: ERROR" >> quality_summary.txt
          echo "Error: Quality check failed to run" >> quality_summary.txt
        fi
        
        if [ ! -f quality_dashboard.md ]; then
          echo "# ğŸ“Š Data Quality Dashboard" > quality_dashboard.md
          echo "" >> quality_dashboard.md
          echo "**Status**: âŒ ERROR - Quality check failed to run" >> quality_dashboard.md
          echo "" >> quality_dashboard.md
          echo "Please check the workflow logs for details." >> quality_dashboard.md
        fi
        
    - name: ğŸš¨ Alert on Quality Issues
      if: steps.quality.outputs.quality_failed == 'true'
      run: |
        echo "ğŸš¨ Data quality issues detected!"
        
        # Read quality summary
        cat quality_summary.txt
        
        echo ""
        echo "ğŸ”— Detailed report: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        
        # In production, you would send alerts here:
        # - Create GitHub issue
        # - Send Slack notification
        # - Email alert
        # - Discord webhook
        
        echo "ğŸ’¡ Configure alert webhooks for production notifications"
        
    - name: ğŸ“¤ Upload Quality Reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quality-report-${{ github.run_number }}
        path: |
          quality_report.json
          quality_dashboard.md
          quality_summary.txt
        retention-days: 60
        
    - name: ğŸ’¾ Update Quality Dashboard
      if: success()
      run: |
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Commit quality dashboard
        git add quality_dashboard.md
        
        if ! git diff --staged --quiet; then
          git commit -m "ğŸ“Š Update data quality dashboard
          
          Quality monitoring results:
          - $(grep 'Quality Score:' quality_summary.txt)
          - $(grep 'Stock Count:' quality_summary.txt)
          - $(grep 'Status:' quality_summary.txt)
          
          ğŸ¤– Automated quality monitoring"
          
          git push
          echo "âœ… Quality dashboard updated"
        fi